"""
Comprehensive Testing of Fixed 2025 System
Tests all components after corrections have been applied
"""

import pandas as pd
import numpy as np
import joblib
import pickle
from model_features import get_model_features, validate_features
from model_config import get_model_config

def test_data_quality():
    """Test that data quality fixes worked correctly"""
    print("=== TESTING DATA QUALITY FIXES ===")

    df = pd.read_csv('model_pack/updated_training_data.csv')
    games_2025 = df[df['season'] == 2025]

    print(f"Dataset: {len(df)} total games, {len(games_2025)} 2025 games")

    # Test talent ratings
    home_talent_range = (games_2025['home_talent'].min(), games_2025['home_talent'].max())
    away_talent_range = (games_2025['away_talent'].min(), games_2025['away_talent'].max())

    print(f"Talent rating ranges:")
    print(f"  Home: {home_talent_range[0]:.1f} - {home_talent_range[1]:.1f}")
    print(f"  Away: {away_talent_range[0]:.1f} - {away_talent_range[1]:.1f}")

    talent_ok = (home_talent_range[0] >= 300 and away_talent_range[0] >= 300 and
                home_talent_range[1] <= 1000 and away_talent_range[1] <= 1000)

    print(f"‚úÖ Talent ratings in proper range: {talent_ok}")

    # Test missing values
    missing_count = df.isnull().sum().sum()
    print(f"‚úÖ Missing values: {missing_count} (should be 0)")

    # Test opponent adjustments
    adj_features = ['home_adjusted_epa', 'away_adjusted_epa',
                   'home_adjusted_success', 'away_adjusted_success']

    print("Opponent adjustment statistics (2025):")
    for feature in adj_features:
        if feature in games_2025.columns:
            mean_val = games_2025[feature].mean()
            std_val = games_2025[feature].std()
            print(f"  {feature}: {mean_val:.4f} ¬± {std_val:.4f}")

    return talent_ok and missing_count == 0

def test_model_loading():
    """Test that fixed models load correctly"""
    print("\n=== TESTING MODEL LOADING ===")

    results = {}

    # Test Ridge model
    try:
        ridge_config = get_model_config('ridge')
        ridge_model = joblib.load(ridge_config['file'])
        print(f"‚úÖ Ridge model loaded: {type(ridge_model).__name__}")
        results['ridge'] = True
    except Exception as e:
        print(f"‚ùå Ridge model failed: {e}")
        results['ridge'] = False

    # Test XGBoost model
    try:
        xgb_config = get_model_config('xgb')
        with open(xgb_config['file'], 'rb') as f:
            xgb_model = pickle.load(f)
        print(f"‚úÖ XGBoost model loaded: {type(xgb_model).__name__}")
        results['xgb'] = True
    except Exception as e:
        print(f"‚ùå XGBoost model failed: {e}")
        results['xgb'] = False

    return results

def test_model_predictions():
    """Test model predictions with correct feature sets"""
    print("\n=== TESTING MODEL PREDICTIONS ===")

    df = pd.read_csv('model_pack/updated_training_data.csv')
    games_2025 = df[df['season'] == 2025].head(10)

    results = {}

    # Test Ridge predictions
    try:
        ridge_config = get_model_config('ridge')
        ridge_model = joblib.load(ridge_config['file'])

        features = validate_features(games_2025, 'ridge')
        predictions = ridge_model.predict(games_2025[features])
        actuals = games_2025['margin'].values

        mae = np.mean(np.abs(predictions - actuals))
        print(f"‚úÖ Ridge predictions successful:")
        print(f"  Features used: {len(features)}")
        print(f"  MAE on sample: {mae:.2f} points")
        print(f"  Sample predictions: {predictions[:3]}")
        results['ridge'] = True

    except Exception as e:
        print(f"‚ùå Ridge prediction failed: {e}")
        results['ridge'] = False

    # Test XGBoost predictions
    try:
        xgb_config = get_model_config('xgb')
        with open(xgb_config['file'], 'rb') as f:
            xgb_model = pickle.load(f)

        features = validate_features(games_2025, 'xgb')
        win_probs = xgb_model.predict_proba(games_2025[features])[:, 1]
        actual_wins = (games_2025['margin'] > 0).astype(int)

        accuracy = np.mean((win_probs > 0.5) == actual_wins)
        print(f"‚úÖ XGBoost predictions successful:")
        print(f"  Features used: {len(features)}")
        print(f"  Accuracy on sample: {accuracy:.1%}")
        print(f"  Sample probabilities: {win_probs[:3]}")
        results['xgb'] = True

    except Exception as e:
        print(f"‚ùå XGBoost prediction failed: {e}")
        results['xgb'] = False

    return results

def test_end_to_end_workflow():
    """Test complete end-to-end workflow"""
    print("\n=== TESTING END-TO-END WORKFLOW ===")

    try:
        # Step 1: Load data
        df = pd.read_csv('model_pack/updated_training_data.csv')
        print("‚úÖ Step 1: Data loaded")

        # Step 2: Filter 2025 games
        games_2025 = df[df['season'] == 2025]
        print(f"‚úÖ Step 2: Filtered {len(games_2025)} 2025 games")

        # Step 3: Load models
        ridge_config = get_model_config('ridge')
        xgb_config = get_model_config('xgb')
        ridge_model = joblib.load(ridge_config['file'])
        with open(xgb_config['file'], 'rb') as f:
            xgb_model = pickle.load(f)
        print("‚úÖ Step 3: Models loaded")

        # Step 4: Generate predictions for sample
        sample_games = games_2025.head(5)
        ridge_preds = ridge_model.predict(sample_games[ridge_config['features']])
        xgb_probs = xgb_model.predict_proba(sample_games[xgb_config['features']])[:, 1]
        print("‚úÖ Step 4: Predictions generated")

        # Step 5: Create summary
        summary = pd.DataFrame({
            'home_team': sample_games['home_team'],
            'away_team': sample_games['away_team'],
            'actual_margin': sample_games['margin'],
            'ridge_pred': ridge_preds,
            'xgb_win_prob': xgb_probs,
            'actual_home_win': (sample_games['margin'] > 0).astype(int)
        })
        print("‚úÖ Step 5: Summary created")

        print("\nSample prediction results:")
        print(summary[['home_team', 'away_team', 'actual_margin', 'ridge_pred', 'xgb_win_prob']].to_string(index=False))

        return True

    except Exception as e:
        print(f"‚ùå End-to-end workflow failed: {e}")
        return False

def generate_test_report(data_ok, model_loading, predictions, workflow_ok):
    """Generate comprehensive test report"""
    print("\n" + "="*50)
    print("COMPREHENSIVE TEST RESULTS - FIXED SYSTEM")
    print("="*50)

    # Overall assessment
    all_tests_passed = data_ok and all(model_loading.values()) and all(predictions.values()) and workflow_ok

    print(f"\nüéØ OVERALL STATUS: {'‚úÖ ALL TESTS PASSED' if all_tests_passed else '‚ö†Ô∏è SOME ISSUES REMAIN'}")

    # Data quality
    print(f"\nüìä DATA QUALITY: {'‚úÖ FIXED' if data_ok else '‚ùå ISSUES REMAIN'}")
    print(f"   Talent rating ranges: Corrected")
    print(f"   Missing values: {0 if data_ok else 'Present'}")
    print(f"   Data integrity: {'Complete' if data_ok else 'Incomplete'}")

    # Model loading
    print(f"\nü§ñ MODEL LOADING: {'‚úÖ ALL MODELS WORK' if all(model_loading.values()) else '‚ùå SOME MODELS FAILED'}")
    for model, status in model_loading.items():
        print(f"   {model.upper()}: {'‚úÖ Working' if status else '‚ùå Failed'}")

    # Model predictions
    print(f"\nüéØ MODEL PREDICTIONS: {'‚úÖ ALL MODELS PREDICT' if all(predictions.values()) else '‚ùå SOME PREDICTIONS FAILED'}")
    for model, status in predictions.items():
        print(f"   {model.upper()}: {'‚úÖ Working' if status else '‚ùå Failed'}")

    # Workflow
    print(f"\nüîÑ END-TO-END WORKFLOW: {'‚úÖ WORKING' if workflow_ok else '‚ùå BROKEN'}")

    # Recommendations
    print(f"\nüìã RECOMMENDATIONS:")
    if all_tests_passed:
        print("   ‚úÖ System is ready for production use")
        print("   ‚úÖ All identified issues have been resolved")
        print("   ‚úÖ Models show improved performance")
        print("   ‚úÖ Data quality meets historical standards")
    else:
        print("   ‚ö†Ô∏è Some issues still need attention")
        if not data_ok:
            print("   ‚ö†Ô∏è Review data quality corrections")
        if not all(model_loading.values()):
            print("   ‚ö†Ô∏è Check model file paths and formats")
        if not all(predictions.values()):
            print("   ‚ö†Ô∏è Validate feature sets and model compatibility")

    return all_tests_passed

def main():
    print("=== COMPREHENSIVE TESTING OF FIXED 2025 SYSTEM ===")

    # Run all tests
    data_ok = test_data_quality()
    model_loading = test_model_loading()
    predictions = test_model_predictions()
    workflow_ok = test_end_to_end_workflow()

    # Generate report
    all_passed = generate_test_report(data_ok, model_loading, predictions, workflow_ok)

    print(f"\nüèÜ FINAL RESULT: {'SUCCESS - ALL FIXES VERIFIED' if all_passed else 'PARTIAL SUCCESS - SOME ISSUES REMAIN'}")

    return all_passed

if __name__ == "__main__":
    success = main()