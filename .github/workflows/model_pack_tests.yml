name: Model Pack Tests and Validation

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'model_pack/**'
      - 'tests/test_model_pack*.py'
      - '.github/workflows/model_pack_tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'model_pack/**'
      - 'tests/test_model_pack*.py'
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:

jobs:
  test:
    name: Run Model Pack Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt || true
        pip install pytest pytest-cov
    
    - name: Run unit tests
      run: |
        pytest tests/test_model_pack_agents.py -v --cov=model_pack --cov-report=term-missing
    
    - name: Run integration tests
      run: |
        pytest tests/test_model_pack_integration.py -v
    
    - name: Run data quality tests
      run: |
        pytest tests/test_data_quality.py -v
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        flags: model_pack
        name: model-pack-coverage
      if: matrix.python-version == '3.13'

  validate-data-quality:
    name: Validate Data Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pandas numpy
    
    - name: Validate training data structure
      run: |
        python -c "
        import pandas as pd
        from pathlib import Path
        data_path = Path('model_pack/updated_training_data.csv')
        if data_path.exists():
            df = pd.read_csv(data_path)
            assert len(df) > 0, 'Training data is empty'
            assert 'season' in df.columns, 'Missing season column'
            assert 'week' in df.columns, 'Missing week column'
            print(f'✅ Training data validation passed: {len(df)} games')
        else:
            print('⚠️ Training data file not found (expected for CI)')
        "
    
    - name: Check for data leakage
      run: |
        python -c "
        import pandas as pd
        from pathlib import Path
        data_path = Path('model_pack/updated_training_data.csv')
        if data_path.exists():
            df = pd.read_csv(data_path)
            # Check temporal ordering
            if 'season' in df.columns:
                seasons = sorted(df['season'].unique())
                print(f'Seasons in data: {seasons}')
                assert len(seasons) > 0, 'No seasons found'
            print('✅ Data leakage check passed')
        "

  test-model-training:
    name: Test Model Training Pipeline
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install scikit-learn xgboost joblib
    
    - name: Test model training (dry run)
      run: |
        python -c "
        from model_pack.model_training_agent import ModelTrainingAgent
        import tempfile
        import pandas as pd
        import numpy as np
        
        # Create minimal test data
        test_data = pd.DataFrame({
            'season': [2020, 2020, 2021, 2021],
            'week': [5, 6, 5, 6],
            'home_team': ['Team A', 'Team B', 'Team A', 'Team B'],
            'away_team': ['Team B', 'Team A', 'Team B', 'Team A'],
            'home_points': [42, 35, 28, 31],
            'away_points': [13, 21, 14, 17],
            'margin': [29, 14, 14, 14],
            'home_talent': [0.85, 0.80, 0.85, 0.80],
            'away_talent': [0.80, 0.85, 0.80, 0.85],
            'home_elo': [1850, 1750, 1850, 1750],
            'away_elo': [1750, 1850, 1750, 1850],
            'home_adjusted_epa': [0.25, 0.18, 0.22, 0.20],
            'home_adjusted_epa_allowed': [-0.10, -0.12, -0.08, -0.11],
            'away_adjusted_epa': [0.10, 0.12, 0.08, 0.11],
            'away_adjusted_epa_allowed': [-0.25, -0.18, -0.22, -0.20],
        })
        
        # Save test data
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            test_data.to_csv(f.name, index=False)
            temp_path = f.name
        
        try:
            agent = ModelTrainingAgent(data_path=temp_path)
            agent.load_and_prepare_data()
            print('✅ Model training agent initialization successful')
        finally:
            import os
            os.unlink(temp_path)
        "
      env:
        CFBD_API_KEY: ${{ secrets.CFBD_API_KEY }}

  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Check model performance
      run: |
        python -c "
        from pathlib import Path
        import json
        
        # Check if performance history exists
        registry_path = Path('model_pack/model_registry.json')
        if registry_path.exists():
            with open(registry_path) as f:
                registry = json.load(f)
            
            print(f'Model registry found: {registry.get(\"last_updated\", \"unknown\")}')
            
            # Check performance metrics
            for model_name, model_info in registry.get('models', {}).items():
                metrics = model_info.get('metrics', {})
                print(f'{model_name}: {metrics}')
        else:
            print('⚠️ Model registry not found (expected for new installations)')
        "

  lint:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 mypy
    
    - name: Check code formatting
      run: |
        black --check model_pack/ --exclude=".*\.ipynb" || true
    
    - name: Lint with flake8
      run: |
        flake8 model_pack/ --count --select=E9,F63,F7,F82 --show-source --statistics || true
    
    - name: Type checking
      run: |
        mypy model_pack/ --ignore-missing-imports || true

