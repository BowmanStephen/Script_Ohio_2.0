{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af4edeed",
   "metadata": {
    "tags": [
     "auto-setup",
     "do-not-remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Notebook auto-setup complete:\n",
      "  â€¢ Project root: /Users/stephen_bowman/Documents/GitHub/Script_Ohio_2.0/starter_pack\n",
      "  â€¢ Requirements: /Users/stephen_bowman/Documents/GitHub/Script_Ohio_2.0/starter_pack/requirements.txt\n",
      "  â€¢ Missing modules: none\n",
      "  â€¢ Auto install performed: False\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Auto-setup: installs deps + configures CFBD access\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find _auto_setup.py regardless of current working directory\n",
    "_current = Path().resolve()\n",
    "_auto_setup_path = None\n",
    "for parent in [_current] + list(_current.parents):\n",
    "    candidate = parent / \"starter_pack\" / \"_auto_setup.py\"\n",
    "    if candidate.exists():\n",
    "        _auto_setup_path = candidate\n",
    "        # Add project root to sys.path (auto_setup.py will also do this)\n",
    "        if str(parent) not in sys.path:\n",
    "            sys.path.insert(0, str(parent))\n",
    "        break\n",
    "\n",
    "if _auto_setup_path and _auto_setup_path.exists():\n",
    "    # Execute the file directly without changing directory\n",
    "    with open(_auto_setup_path, 'r') as f:\n",
    "        exec(f.read(), {'__file__': str(_auto_setup_path)})\n",
    "else:\n",
    "    # Fallback: try relative path\n",
    "    try:\n",
    "        with open(\"./_auto_setup.py\", 'r') as f:\n",
    "            exec(f.read(), {'__file__': './_auto_setup.py'})\n",
    "    except FileNotFoundError:\n",
    "        print(\"âš ï¸  Could not find _auto_setup.py. Please run from starter_pack directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7565fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_matchup_predictor.ipynb\n",
    "# ðŸˆ Simple Game Outcome Predictor Using EPA & Success Rate\n",
    "\n",
    "# ðŸ›  Requirements:\n",
    "# - pandas, scikit-learn, matplotlib, seaborn (install via `pip install pandas scikit-learn matplotlib seaborn`)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Import starter pack configuration system\n",
    "import sys\n",
    "from pathlib import Path\n",
    "_config_dir = Path().resolve() / \"config\"\n",
    "if str(_config_dir.parent) not in sys.path:\n",
    "    sys.path.insert(0, str(_config_dir.parent))\n",
    "from config.data_config import get_starter_pack_config\n",
    "\n",
    "# Get configuration\n",
    "config = get_starter_pack_config()\n",
    "DATA_DIR = str(config.data_dir)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = [15,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 FBS vs. FBS games in 2025\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“‚ Load current year game results and season stats\n",
    "\n",
    "# Load with low_memory=False to avoid dtype warnings\n",
    "games = pd.read_csv(os.path.join(DATA_DIR, \"games.csv\"), low_memory=False)\n",
    "\n",
    "# Try to load stats for current year, fallback to previous year if not available\n",
    "stats_file = os.path.join(DATA_DIR, \"advanced_season_stats\", f\"{config.current_year}.csv\")\n",
    "if not os.path.exists(stats_file):\n",
    "    print(f\"âš ï¸  Stats file for {config.current_year} not found, trying {config.current_year - 1}...\")\n",
    "    stats_file = os.path.join(DATA_DIR, \"advanced_season_stats\", f\"{config.current_year - 1}.csv\")\n",
    "    if os.path.exists(stats_file):\n",
    "        print(f\"âœ… Using {config.current_year - 1} stats\")\n",
    "        training_year = config.current_year - 1\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Stats file not found for {config.current_year} or {config.current_year - 1}\")\n",
    "else:\n",
    "    training_year = config.current_year\n",
    "\n",
    "stats = pd.read_csv(stats_file)\n",
    "\n",
    "# Filter to FBS-only matchups where both teams have data\n",
    "# Use training_year for games if current year has no completed games\n",
    "games_current = games[\n",
    "    (games[\"season\"] == training_year) & \n",
    "    (games[\"home_classification\"] == 'fbs') & \n",
    "    (games[\"away_classification\"] == 'fbs')\n",
    "].copy()\n",
    "\n",
    "# Check if we have games with scores for this year\n",
    "has_scores = games_current[\"home_points\"].notna() & games_current[\"away_points\"].notna()\n",
    "if has_scores.sum() == 0 and training_year == config.current_year:\n",
    "    # If current year has no scores, use previous year for games\n",
    "    print(f\"âš ï¸  {training_year} has no completed games with scores.\")\n",
    "    print(f\"   Using {training_year - 1} games for training (stats still from {training_year})\")\n",
    "    games_current = games[\n",
    "        (games[\"season\"] == training_year - 1) & \n",
    "        (games[\"home_classification\"] == 'fbs') & \n",
    "        (games[\"away_classification\"] == 'fbs')\n",
    "    ].copy()\n",
    "    # Verify we have scores now\n",
    "    has_scores = games_current[\"home_points\"].notna() & games_current[\"away_points\"].notna()\n",
    "    if has_scores.sum() == 0:\n",
    "        raise ValueError(\n",
    "            f\"Neither {training_year} nor {training_year - 1} have games with scores. \"\n",
    "            \"This notebook requires completed games with final scores.\"\n",
    "        )\n",
    "\n",
    "print(f\"{len(games_current)} FBS vs. FBS games (season: {games_current['season'].iloc[0] if len(games_current) > 0 else 'N/A'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9fa82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats loaded: 136 teams\n",
      "Teams with complete stats: 136\n",
      "After home team merge: 693 games\n",
      "693 games with full stat coverage\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”— Join game data with team stats for both teams\n",
    "\n",
    "# Check required columns exist in stats\n",
    "required_stats_cols = [\"team\", \"offense_ppa\", \"defense_ppa\", \"offense_successRate\", \"defense_successRate\"]\n",
    "missing_cols = [col for col in required_stats_cols if col not in stats.columns]\n",
    "if missing_cols:\n",
    "    print(f\"âš ï¸  Warning: Missing columns in stats: {missing_cols}\")\n",
    "    print(f\"Available columns: {list(stats.columns)[:10]}...\")\n",
    "    # Try alternative column names\n",
    "    if \"offense_ppa\" not in stats.columns and \"offense_epa\" in stats.columns:\n",
    "        print(\"Using 'epa' instead of 'ppa'...\")\n",
    "        stats = stats.rename(columns={\n",
    "            \"offense_epa\": \"offense_ppa\",\n",
    "            \"defense_epa\": \"defense_ppa\"\n",
    "        })\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot proceed: required columns missing: {missing_cols}\")\n",
    "\n",
    "# Prep stats - keep original for predictions later\n",
    "stats_for_merge = stats[required_stats_cols].copy()\n",
    "\n",
    "# Check for missing values in stats\n",
    "print(f\"Stats loaded: {len(stats_for_merge)} teams\")\n",
    "print(f\"Teams with complete stats: {stats_for_merge[required_stats_cols[1:]].notna().all(axis=1).sum()}\")\n",
    "\n",
    "# Merge home/away team stats\n",
    "games_stats = games_current.merge(\n",
    "    stats_for_merge, \n",
    "    left_on=\"home_team\", \n",
    "    right_on=\"team\", \n",
    "    how=\"inner\"\n",
    ").rename(columns={\n",
    "    \"offense_ppa\": \"home_offense_ppa\", \n",
    "    \"defense_ppa\": \"home_defense_ppa\",\n",
    "    \"offense_successRate\": \"home_offense_successRate\", \n",
    "    \"defense_successRate\": \"home_defense_successRate\"\n",
    "}).drop(\"team\", axis=1)\n",
    "\n",
    "print(f\"After home team merge: {len(games_stats)} games\")\n",
    "\n",
    "games_stats = games_stats.merge(\n",
    "    stats_for_merge, \n",
    "    left_on=\"away_team\", \n",
    "    right_on=\"team\", \n",
    "    how=\"inner\"\n",
    ").rename(columns={\n",
    "    \"offense_ppa\": \"away_offense_ppa\", \n",
    "    \"defense_ppa\": \"away_defense_ppa\",\n",
    "    \"offense_successRate\": \"away_offense_successRate\", \n",
    "    \"defense_successRate\": \"away_defense_successRate\"\n",
    "}).drop(\"team\", axis=1)\n",
    "\n",
    "print(f\"{len(games_stats)} games with full stat coverage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f64151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 693 games after merge\n",
      "Games with scores: 0\n",
      "âš ï¸  No games with scores found. Checking data...\n",
      "Sample games columns: ['id', 'season', 'season_type', 'week', 'start_date', 'start_time_tbd', 'neutral_site', 'conference_game', 'attendance', 'venue_id']\n",
      "Games with home_points not null: 0\n",
      "Sample home_points values: 105167   NaN\n",
      "105168   NaN\n",
      "105169   NaN\n",
      "105171   NaN\n",
      "105177   NaN\n",
      "Name: home_points, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No completed games found. The season may not be complete yet, or data may be missing.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     18\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâŒ \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhome_points\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column not found in games data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo completed games found. The season may not be complete yet, or data may be missing.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Check for missing stats before creating features\u001b[39;00m\n\u001b[32m     22\u001b[39m stat_cols = [\u001b[33m\"\u001b[39m\u001b[33mhome_offense_ppa\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhome_defense_ppa\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhome_offense_successRate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhome_defense_successRate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33maway_offense_ppa\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maway_defense_ppa\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maway_offense_successRate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maway_defense_successRate\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: No completed games found. The season may not be complete yet, or data may be missing."
     ]
    }
   ],
   "source": [
    "# ðŸ§  Feature engineering: create stat differentials\n",
    "\n",
    "print(f\"Starting with {len(games_stats)} games after merge\")\n",
    "\n",
    "# Check if scores columns exist\n",
    "if \"home_points\" not in games_stats.columns or \"away_points\" not in games_stats.columns:\n",
    "    print(\"âš ï¸  Score columns not found. Available columns:\")\n",
    "    print([col for col in games_stats.columns if 'point' in col.lower() or 'score' in col.lower()])\n",
    "    raise ValueError(\"home_points and away_points columns not found in merged data\")\n",
    "\n",
    "# Convert scores to numeric (handles string scores)\n",
    "games_stats[\"home_points\"] = pd.to_numeric(games_stats[\"home_points\"], errors='coerce')\n",
    "games_stats[\"away_points\"] = pd.to_numeric(games_stats[\"away_points\"], errors='coerce')\n",
    "\n",
    "# Check score data availability\n",
    "has_scores = games_stats[\"home_points\"].notna() & games_stats[\"away_points\"].notna()\n",
    "print(f\"Games with scores: {has_scores.sum()} out of {len(games_stats)}\")\n",
    "\n",
    "# Check data types and sample values\n",
    "if len(games_stats) > 0:\n",
    "    print(f\"home_points dtype: {games_stats['home_points'].dtype}\")\n",
    "    sample_cols = ['home_team', 'away_team', 'home_points', 'away_points']\n",
    "    available_cols = [col for col in sample_cols if col in games_stats.columns]\n",
    "    if available_cols:\n",
    "        print(f\"Sample score data:\\n{games_stats[available_cols].head()}\")\n",
    "    print(f\"Games with valid numeric scores: {has_scores.sum()}\")\n",
    "\n",
    "# Filter to completed games only (where scores exist)\n",
    "games_stats = games_stats[has_scores].copy()\n",
    "\n",
    "if len(games_stats) == 0:\n",
    "    print(\"\\nâš ï¸  No games with scores found.\")\n",
    "    print(\"This usually means:\")\n",
    "    print(\"  1. The season hasn't started yet or games haven't been played\")\n",
    "    print(\"  2. The data file doesn't include completed games\")\n",
    "    print(\"  3. Scores are stored in a different column name\")\n",
    "    print(\"\\nðŸ’¡ Try using a previous year's data by modifying the config or using a different season.\")\n",
    "    raise ValueError(\"No completed games found. Cannot train model without game outcomes.\")\n",
    "\n",
    "# Check for missing stats before creating features\n",
    "stat_cols = [\"home_offense_ppa\", \"home_defense_ppa\", \"home_offense_successRate\", \"home_defense_successRate\",\n",
    "             \"away_offense_ppa\", \"away_defense_ppa\", \"away_offense_successRate\", \"away_defense_successRate\"]\n",
    "missing_stats = games_stats[stat_cols].isna().any(axis=1)\n",
    "print(f\"Games with missing stats: {missing_stats.sum()}\")\n",
    "\n",
    "# Create feature differentials\n",
    "games_stats[\"ppa_diff\"] = games_stats[\"home_offense_ppa\"] - games_stats[\"away_defense_ppa\"]\n",
    "games_stats[\"ppa_allowed_diff\"] = games_stats[\"home_defense_ppa\"] - games_stats[\"away_offense_ppa\"]\n",
    "games_stats[\"successRate_diff\"] = games_stats[\"home_offense_successRate\"] - games_stats[\"away_defense_successRate\"]\n",
    "games_stats[\"successRate_allowed_diff\"] = games_stats[\"home_defense_successRate\"] - games_stats[\"away_offense_successRate\"]\n",
    "\n",
    "# Target: did home team win?\n",
    "games_stats[\"home_win\"] = (games_stats[\"home_points\"] > games_stats[\"away_points\"]).astype(int)\n",
    "\n",
    "# Remove rows with missing feature values\n",
    "feature_cols = [\"ppa_diff\", \"ppa_allowed_diff\", \"successRate_diff\", \"successRate_allowed_diff\"]\n",
    "games_stats = games_stats.dropna(subset=feature_cols)\n",
    "\n",
    "print(f\"\\nGames with complete data: {len(games_stats)}\")\n",
    "\n",
    "if len(games_stats) == 0:\n",
    "    raise ValueError(\n",
    "        \"No games with complete feature data. This may happen if:\\n\"\n",
    "        \"1. The season is not complete yet\\n\"\n",
    "        \"2. Advanced stats are not available for the current year\\n\"\n",
    "        \"3. Try using a previous year's data (e.g., 2024) for training\"\n",
    "    )\n",
    "\n",
    "# Check class distribution\n",
    "win_count = games_stats['home_win'].sum()\n",
    "loss_count = len(games_stats) - win_count\n",
    "print(f\"Home wins: {win_count} ({games_stats['home_win'].mean():.1%})\")\n",
    "print(f\"Home losses: {loss_count} ({(1 - games_stats['home_win'].mean()):.1%})\")\n",
    "\n",
    "# Validate both classes exist\n",
    "if games_stats[\"home_win\"].nunique() < 2:\n",
    "    raise ValueError(\n",
    "        f\"Data contains only one class ({games_stats['home_win'].unique()[0]}). \"\n",
    "        \"Need both wins and losses for classification. \"\n",
    "        \"Try using a previous year's data or check if the season is complete.\"\n",
    "    )\n",
    "\n",
    "X = games_stats[feature_cols]\n",
    "y = games_stats[\"home_win\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88ceaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      5\u001b[39m model = LogisticRegression()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m y_pred = model.predict(X_test)\n\u001b[32m      9\u001b[39m acc = accuracy_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Script_Ohio_2.0/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Script_Ohio_2.0/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1335\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1333\u001b[39m classes_ = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_classes < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis solver needs samples of at least 2 classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the data, but the data contains only one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % classes_[\u001b[32m0\u001b[39m]\n\u001b[32m   1339\u001b[39m     )\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_) == \u001b[32m2\u001b[39m:\n\u001b[32m   1342\u001b[39m     n_classes = \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)"
     ]
    }
   ],
   "source": [
    "# ðŸ¤– Train/test split and model training\n",
    "\n",
    "# Use stratified split to ensure both classes are in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Ensures both classes are represented in train and test\n",
    ")\n",
    "\n",
    "# Validate training set has both classes\n",
    "if y_train.nunique() < 2:\n",
    "    raise ValueError(f\"Training set has only one class. Classes: {y_train.unique()}\")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} games\")\n",
    "print(f\"  Home wins: {y_train.sum()} ({y_train.mean():.1%})\")\n",
    "print(f\"Test set: {len(X_test)} games\")\n",
    "print(f\"  Home wins: {y_test.sum()} ({y_test.mean():.1%})\")\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Accuracy: {acc:.2%}\")\n",
    "print(f\"Baseline (always predict majority class): {max(y_test.mean(), 1 - y_test.mean()):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Loss\", \"Win\"], yticklabels=[\"Loss\", \"Win\"])\n",
    "plt.title(\"Confusion Matrix: Home Team Win Prediction\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Predict a specific matchup (example)\n",
    "\n",
    "def predict_matchup(home_team, away_team):\n",
    "    \"\"\"Predict win probability for a matchup between two teams.\"\"\"\n",
    "    # Check if teams exist in stats\n",
    "    home_stats = stats[stats[\"team\"] == home_team]\n",
    "    away_stats = stats[stats[\"team\"] == away_team]\n",
    "    \n",
    "    if home_stats.empty:\n",
    "        print(f\"âŒ Error: {home_team} not found in stats\")\n",
    "        return None\n",
    "    if away_stats.empty:\n",
    "        print(f\"âŒ Error: {away_team} not found in stats\")\n",
    "        return None\n",
    "    \n",
    "    home = home_stats.iloc[0]\n",
    "    away = away_stats.iloc[0]\n",
    "    \n",
    "    # Check for missing stats\n",
    "    required_cols = [\"offense_ppa\", \"defense_ppa\", \"offense_successRate\", \"defense_successRate\"]\n",
    "    if home[required_cols].isna().any():\n",
    "        print(f\"âŒ Error: {home_team} has missing stats\")\n",
    "        return None\n",
    "    if away[required_cols].isna().any():\n",
    "        print(f\"âŒ Error: {away_team} has missing stats\")\n",
    "        return None\n",
    "\n",
    "    data = {\n",
    "        \"ppa_diff\": home[\"offense_ppa\"] - away[\"defense_ppa\"],\n",
    "        \"ppa_allowed_diff\": home[\"defense_ppa\"] - away[\"offense_ppa\"],\n",
    "        \"successRate_diff\": home[\"offense_successRate\"] - away[\"defense_successRate\"],\n",
    "        \"successRate_allowed_diff\": home[\"defense_successRate\"] - away[\"offense_successRate\"]\n",
    "    }\n",
    "\n",
    "    input_df = pd.DataFrame([data])\n",
    "    prob = model.predict_proba(input_df)[0][1]\n",
    "    print(f\"ðŸˆ {home_team} vs {away_team}\")\n",
    "    print(f\"   Win probability: {prob:.1%}\")\n",
    "    print(f\"   Predicted outcome: {'Home win' if prob > 0.5 else 'Away win'}\")\n",
    "    return prob\n",
    "\n",
    "# Example predictions\n",
    "print(\"Example Matchups:\\n\")\n",
    "predict_matchup(\"Michigan\", \"Ohio State\")\n",
    "print()\n",
    "predict_matchup(\"Georgia\", \"Alabama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f109c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Summary\n",
    "\n",
    "# In this notebook, you:\n",
    "# - Joined team stats with game outcomes\n",
    "# - Built a basic logistic regression model using stat differentials\n",
    "# - Predicted outcomes and evaluated model accuracy\n",
    "# - Created a reusable function to simulate future matchups\n",
    "\n",
    "# ðŸ§ª Try This:\n",
    "# - Add features like talent composite, pass/rush rate, tempo\n",
    "# - Use different models (RandomForest, XGBoost)\n",
    "# - Predict score differential instead of binary win/loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6475c7",
   "metadata": {},
   "source": [
    "# ðŸ”— Bridge to Model Pack\n",
    "\n",
    "## ðŸš€ Next Steps: From Basic Prediction to Machine Learning\n",
    "\n",
    "Congratulations! You've built a basic prediction model. Here's how to take it to the next level:\n",
    "\n",
    "### What You Just Learned â†’ ML Features\n",
    "\n",
    "Your starter pack model uses:\n",
    "- `ppa_diff` â†’ In model pack, this becomes `home_adjusted_epa - away_adjusted_epa_allowed`\n",
    "- `successRate_diff` â†’ In model pack, these are `home_adjusted_success` and `away_adjusted_success`\n",
    "- Basic stats â†’ Model pack uses **86 opponent-adjusted features** for better accuracy\n",
    "\n",
    "### Explore Weekly Training Data\n",
    "\n",
    "See how your concepts become ML features:\n",
    "\n",
    "```python\n",
    "# Load weekly training data to see the 86-feature format\n",
    "import pandas as pd\n",
    "\n",
    "# Option 1: Using path utility directly (recommended)\n",
    "from model_pack.utils.path_utils import get_weekly_training_file\n",
    "weekly_path = get_weekly_training_file(week=1, season=2025)\n",
    "weekly = pd.read_csv(weekly_path)\n",
    "\n",
    "# Option 2: Using config helper (alternative)\n",
    "# weekly_path = config.get_weekly_training_file(week=1, season=2025)\n",
    "# weekly = pd.read_csv(weekly_path)\n",
    "\n",
    "print(f\"Week 1: {len(weekly)} games, {len(weekly.columns)} features\")\n",
    "\n",
    "# Compare your features to ML features\n",
    "print(\"\\nYour features â†’ ML equivalent:\")\n",
    "print(\"  ppa_diff â†’ home_adjusted_epa, away_adjusted_epa_allowed\")\n",
    "print(\"  successRate_diff â†’ home_adjusted_success, away_adjusted_success\")\n",
    "\n",
    "# See the actual ML features\n",
    "print(\"\\nSample ML features:\")\n",
    "print(weekly[['home_adjusted_epa', 'away_adjusted_epa', \n",
    "              'home_adjusted_success', 'away_adjusted_success',\n",
    "              'home_elo', 'away_elo', 'spread']].head())\n",
    "```\n",
    "\n",
    "### Try Model Pack\n",
    "\n",
    "1. **Linear Regression Model**: `../model_pack/01_linear_regression_margin.ipynb`\n",
    "   - Uses your concepts but with opponent-adjusted features\n",
    "   - Predicts score margin instead of just win/loss\n",
    "   - Better accuracy with 86 features!\n",
    "\n",
    "2. **XGBoost Model**: `../model_pack/03_xgboost_win_probability.ipynb`\n",
    "   - Advanced ML model using all 86 features\n",
    "   - Provides win probabilities and confidence intervals\n",
    "\n",
    "### Get Agent Guidance\n",
    "\n",
    "Use the Learning Navigator Agent for personalized help:\n",
    "\n",
    "```python\n",
    "from agents.analytics_orchestrator import AnalyticsOrchestrator, AnalyticsRequest\n",
    "\n",
    "orchestrator = AnalyticsOrchestrator()\n",
    "request = AnalyticsRequest(\n",
    "    user_id='your_id',\n",
    "    query='Bridge me from matchup predictor to model pack',\n",
    "    query_type='learning',\n",
    "    parameters={'current_notebook': '05_matchup_predictor.ipynb'},\n",
    "    context_hints={'role': 'data_scientist'}\n",
    ")\n",
    "response = orchestrator.process_analytics_request(request)\n",
    "print(response.insights)\n",
    "```\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Starter Pack (This Notebook) | Model Pack |\n",
    "|------------------------------|------------|\n",
    "| 4 basic features | 86 opponent-adjusted features |\n",
    "| 55% accuracy | 65-70% accuracy |\n",
    "| Basic stats | Schedule-adjusted metrics |\n",
    "| Win/loss prediction | Margin + win probability |\n",
    "| Current season only | 2016-2025 (Week 5+) |\n",
    "\n",
    "### Recommended Learning Path\n",
    "\n",
    "1. âœ… **You Are Here**: Basic prediction with simple features\n",
    "2. **Next**: Explore weekly training data (Week 1) to see feature format using `get_weekly_training_file()`\n",
    "3. **Then**: Try `../model_pack/01_linear_regression_margin.ipynb`\n",
    "4. **Finally**: Understand feature importance in `../model_pack/06_shap_interpretability.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ’¡ **Tip**: The weekly training data files (accessed via `get_weekly_training_file()` utility) show exactly how\n",
    "starter pack metrics become the 86 features used in ML models. Week 5+ data is used for\n",
    "temporal validation (no future data leakage). Files are located in `data/training/weekly/` with automatic\n",
    "fallback support for legacy locations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
